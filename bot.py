# bot.py
import telebot
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
import re
import logging
from datetime import datetime

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================
BOT_TOKEN = "8450391232:AAGtconwAu_Lig4gre6k05NJgXWukh6NIHU"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ç–æ–∫–µ–Ω –æ—Ç @BotFather
MODEL_PATH = "./my_rugpt3_finetuned"  # –ü—É—Ç—å –∫ –≤–∞—à–µ–π –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("bot.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ====================
try:
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = model.to(device)
    model.eval()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    exit(1)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
try:
    bot = telebot.TeleBot(BOT_TOKEN)
    print("‚úÖ –ë–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ—Ç–∞: {e}")
    exit(1)

# ==================== –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò ====================
def clean_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞"""
    if not text:
        return ""
    text = str(text)
    text = re.sub(r'http\S+', '', text)           # –°—Å—ã–ª–∫–∏
    text = re.sub(r'[^\w\s\.\,\!\?\:\;\-\+\"\'\(\)\‚Äî]', ' ', text)
    text = re.sub(r'\s+', ' ', text)              # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    return text.strip()

def generate_response(question, max_length=150, temperature=0.7):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    try:
        # –û—á–∏—â–∞–µ–º –≤–æ–ø—Ä–æ—Å
        cleaned_question = clean_text(question)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
        prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {cleaned_question}\n–°–∏—Å—Ç–µ–º–∞:"
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        inputs = tokenizer(
            prompt, 
            return_tensors="pt", 
            max_length=512, 
            truncation=True
        ).to(device)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_length=len(inputs.input_ids[0]) + max_length,
                num_return_sequences=1,
                temperature=temperature,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id,
                repetition_penalty=1.1,  # –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
                top_p=0.9,              # Nucleus sampling
                top_k=50,               # Top-k sampling
            )
        
        # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç —Å–∏—Å—Ç–µ–º—ã (–ø–æ—Å–ª–µ "–°–∏—Å—Ç–µ–º–∞:")
        if "–°–∏—Å—Ç–µ–º–∞:" in generated_text:
            response = generated_text.split("–°–∏—Å—Ç–µ–º–∞:")[1].strip()
        else:
            # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ –ø—Ä–æ–º–ø—Ç–∞
            response = generated_text.replace(prompt, "").strip()
        
        # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        response = re.sub(r'[^\.\!\?]$', '.', response)  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –µ—Å–ª–∏ –Ω–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        response = re.sub(r'\s+', ' ', response).strip()
        
        return response
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."

# ==================== –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î ====================
@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥ /start –∏ /help"""
    welcome_text = """
ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ —á–∞—Ç-–±–æ—Ç —Ç–µ—Ö–Ω–∏–∫—É–º–∞!

–Ø –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ:
‚Ä¢ –†–∞—Å–ø–∏—Å–∞–Ω–∏–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–µ —Ä–∞–±–æ—Ç—ã
‚Ä¢ –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–∏ –∏ –ø–µ—Ä–µ–≤–æ–¥–µ
‚Ä¢ –£—á–µ–±–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ
‚Ä¢ –ë–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
‚Ä¢ –ò –º–Ω–æ–≥–æ–º –¥—Ä—É–≥–æ–º

–ü—Ä–æ—Å—Ç–æ –∑–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ!

üìã –ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:
- "–ö–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —é—Ä–∏—Å—Ç?"
- "–ö–∞–∫ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏—Å—å –Ω–∞ –¥—Ä—É–≥—É—é —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å?"
- "–ö–∞–∫–∏–µ —è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑—É—á–∞—é—Ç?"

–ö–æ–º–∞–Ω–¥—ã:
/start - –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É
/help - –ø–æ–º–æ—â—å
/status - —Å—Ç–∞—Ç—É—Å –±–æ—Ç–∞
    """
    bot.reply_to(message, welcome_text)

@bot.message_handler(commands=['status'])
def send_status(message):
    """–°—Ç–∞—Ç—É—Å –±–æ—Ç–∞ –∏ –º–æ–¥–µ–ª–∏"""
    status_text = f"""
üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:
‚Ä¢ –ú–æ–¥–µ–ª—å: RuGPT3 (–¥–æ–æ–±—É—á–µ–Ω–Ω–∞—è)
‚Ä¢ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}
‚Ä¢ –í—Ä–µ–º—è: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
‚Ä¢ –ü–∞–º—è—Ç—å GPU: {torch.cuda.memory_allocated() / 1024**3:.2f} GB (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)

‚úÖ –ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    """
    bot.reply_to(message, status_text)

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    try:
        user_id = message.from_user.id
        username = message.from_user.username or "Unknown"
        question = message.text
        
        logger.info(f"üë§ –í–æ–ø—Ä–æ—Å –æ—Ç {username} ({user_id}): {question}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –±–æ—Ç –ø–µ—á–∞—Ç–∞–µ—Ç
        bot.send_chat_action(message.chat.id, 'typing')
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = generate_response(question)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        logger.info(f"ü§ñ –û—Ç–≤–µ—Ç –¥–ª—è {username}: {response[:100]}...")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        bot.reply_to(message, response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        bot.reply_to(message, "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –µ—â–µ —Ä–∞–∑.")

# ==================== –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö ====================
def error_handler(update, context):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫"""
    logger.error(f"–û—à–∏–±–∫–∞ –≤ update {update}: {context.error}")

# ==================== –ó–ê–ü–£–°–ö –ë–û–¢–ê ====================
if __name__ == "__main__":
    print("=" * 50)
    print("ü§ñ –ó–ê–ü–£–°–ö –¢–ï–õ–ï–ì–†–ê–ú –ë–û–¢–ê")
    print(f"üìç –ú–æ–¥–µ–ª—å: {MODEL_PATH}")
    print(f"‚öôÔ∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    print("üì± –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ...")
    print("=" * 50)
    
    try:
        # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
        bot.infinity_polling(timeout=60, long_pending=True)
        
    except KeyboardInterrupt:
        print("\nüõë –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–æ—Ç–∞: {e}")
